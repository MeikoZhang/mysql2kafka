#============== server配置 ===================
#启用shutdown
endpoints.shutdown.enabled=true
#禁用密码验证
endpoints.shutdown.sensitive=false

#设置Tomcat端口，默认8080
server.port=8080
#设置项目ContextPath
server.context-path=/
#设置Tomcat编码
server.tomcat.uri-encoding=UTF-8


#============== canal server配置 ===================
canal_address=172.16.25.71
canal_port=11111
canal_destination=mysql78
canal_username=
canal_password=
canal_batchSize=1000
canal_subscribe=ucard_loan.customer_info,ucard_loan.order_info,ucard_loan.order_flow

##============== web视图解析配置 ===================
#设置视图解析器路径
#spring.mvc.view.prefix=/WEB-INF/views/
#设置视图解析器后缀
#spring.mvc.view.suffix=.jsp

#============== 数据库信息配置 ===================
#数据库配置
#spring.datasource.driver-class-name=com.mysql.jdbc.Driver
#spring.datasource.url=jdbc:mysql://172.16.25.78:3308/als7db?useUnicode=true&characterEncoding=utf-8&zeroDateTimeBehavior=convertToNull&allowMultiQueries=true
#spring.datasource.username=big_data
#spring.datasource.password=4ZooYq2ZALYjTYDyl04cySVUEsv
#spring.datasource.type=com.alibaba.druid.pool.DruidDataSource

#============== mybatis配置 ===================
#配置.xml文件路径
#mybatis.mapperLocations=classpath:com/sixku/mysql2kakfa/dao/*.xml
#mybatis.config-location=classpath:mybatis-config.xml
#配置模型路径
#mybatis.typeAliasesPackage=com.sixku.mysql2kafka.dao.domain

# als7db datasource config
als7db.datasource.driverClassName=com.mysql.jdbc.Driver
als7db.datasource.url=jdbc:mysql://172.16.25.78:3307/als7db?useUnicode=true&characterEncoding=utf-8&zeroDateTimeBehavior=convertToNull&allowMultiQueries=true
als7db.datasource.username=big_data
als7db.datasource.password=4ZooYq2ZALYjTYDyl04cySVUEsv
als7db.datasource.type=com.alibaba.druid.pool.DruidDataSource
# 以下为连接池的相关参数配置
# 初始化大小，最小，最大
als7db.datasource.initialSize=5
als7db.datasource.maxIdle=20
als7db.datasource.minIdle=5
# 配置获取连接等待超时的时间
als7db.datasource.maxWait=60000
# 验证连接是否有效。此参数必须设置为非空字符串，下面三项设置成true才能生效
als7db.datasource.validationQuery=SELECT 1
# 指明是否在从池中取出连接前进行检验,如果检验失败,则从池中去除连接并尝试取出另一个
als7db.datasource.testOnBorrow=false
# 指明连接是否被空闲连接回收器(如果有)进行检验.如果检测失败,则连接将被从池中去除.
als7db.datasource.testWhileIdle=true
# 指明是否在归还到池中前进行检验
als7db.datasource.testOnReturn=false
# 配置间隔多久才进行一次检测，检测需要关闭的空闲连接，单位是毫秒
als7db.datasource.timeBetweenEvictionRunsMillis=60000
als7db.datasource.minEvictableIdleTimeMillis=300000
als7db.datasource.poolPreparedStatements=true
als7db.datasource.maxPoolPreparedStatementPerConnectionSize=20


# ucard datasource config
ucard.datasource.driverClassName=com.mysql.jdbc.Driver
ucard.datasource.url=jdbc:mysql://172.16.25.78:3308/ucard_loan?useUnicode=true&characterEncoding=utf-8&zeroDateTimeBehavior=convertToNull&allowMultiQueries=true
ucard.datasource.username=big_data
ucard.datasource.password=4ZooYq2ZALYjTYDyl04cySVUEsv
ucard.datasource.type=com.alibaba.druid.pool.DruidDataSource
ucard.datasource.initialSize=5
ucard.datasource.maxIdle=20
ucard.datasource.minIdle=5
ucard.datasource.maxWait=60000
ucard.datasource.validationQuery=SELECT 1
ucard.datasource.testOnBorrow=false
ucard.datasource.testWhileIdle=true
ucard.datasource.testOnReturn=false
ucard.datasource.timeBetweenEvictionRunsMillis=60000
ucard.datasource.minEvictableIdleTimeMillis=300000
ucard.datasource.poolPreparedStatements=true
ucard.datasource.maxPoolPreparedStatementPerConnectionSize=20


#============== kafka ===================
# 指定kafka 代理地址，可以多个
spring.kafka.bootstrap-servers=172.16.25.75:6667,172.16.25.76:6667,172.16.25.77:6667
#========= provider ==========
spring.kafka.producer.retries=0
# 每次批量发送消息的数量
spring.kafka.producer.batch-size=16384
spring.kafka.producer.buffer-memory=33554432
# 指定消息key和消息体的编解码方式
spring.kafka.producer.key-serializer=org.apache.kafka.common.serialization.StringSerializer
spring.kafka.producer.value-serializer=org.apache.kafka.common.serialization.StringSerializer

#========== consumer ==========
# 指定默认消费者group id
spring.kafka.consumer.group-id=group-ucard
# earliest /latest /none
spring.kafka.consumer.auto-offset-reset=earliest
spring.kafka.consumer.enable-auto-commit=true
spring.kafka.consumer.auto-commit-interval=100
# 指定消息key和消息体的编解码方式
spring.kafka.consumer.key-deserializer=org.apache.kafka.common.serialization.StringDeserializer
spring.kafka.consumer.value-deserializer=org.apache.kafka.common.serialization.StringDeserializer
